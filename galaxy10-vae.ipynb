{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7246791,"sourceType":"datasetVersion","datasetId":4198136}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"''# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-23T14:13:14.891861Z","iopub.execute_input":"2023-12-23T14:13:14.892340Z","iopub.status.idle":"2023-12-23T14:13:15.237350Z","shell.execute_reply.started":"2023-12-23T14:13:14.892312Z","shell.execute_reply":"2023-12-23T14:13:15.236446Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/galaxy10/images.npy\n/kaggle/input/galaxy10/labels.npy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"***Hello everyone, in this notebook I am going to use semi-supervised learning approach for the image analysis of the Galaxy10 dataset. It is a use dataset of shape 21785 * 69 * 69. Here\nI am using VAE along with a custom ANN model,We basically trained VAE on a minimum reconstruction loss, then extract the encoder part ,freeze its weights and on the base of the encoder we use a dense layer for the task of the image classification.***","metadata":{}},{"cell_type":"markdown","source":"# Loading of the datasets","metadata":{}},{"cell_type":"code","source":"train1=np.load(\"/kaggle/input/galaxy10/images.npy\")","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:13:44.471560Z","iopub.execute_input":"2023-12-23T14:13:44.472460Z","iopub.status.idle":"2023-12-23T14:13:48.419312Z","shell.execute_reply.started":"2023-12-23T14:13:44.472428Z","shell.execute_reply":"2023-12-23T14:13:48.418512Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"target=np.load('/kaggle/input/galaxy10/labels.npy')","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:13:55.466534Z","iopub.execute_input":"2023-12-23T14:13:55.466891Z","iopub.status.idle":"2023-12-23T14:13:55.479715Z","shell.execute_reply.started":"2023-12-23T14:13:55.466866Z","shell.execute_reply":"2023-12-23T14:13:55.478996Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"target.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-23T10:41:53.064281Z","iopub.execute_input":"2023-12-23T10:41:53.064618Z","iopub.status.idle":"2023-12-23T10:41:53.071692Z","shell.execute_reply.started":"2023-12-23T10:41:53.064592Z","shell.execute_reply":"2023-12-23T10:41:53.070735Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(21785,)"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport tensorflow as tf\nimport keras\nfrom keras import layers","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:14:03.336147Z","iopub.execute_input":"2023-12-23T14:14:03.336504Z","iopub.status.idle":"2023-12-23T14:14:14.002662Z","shell.execute_reply.started":"2023-12-23T14:14:03.336477Z","shell.execute_reply":"2023-12-23T14:14:14.001670Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Sampling Layer","metadata":{}},{"cell_type":"code","source":"\nclass Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.random.normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:14:27.721484Z","iopub.execute_input":"2023-12-23T14:14:27.722560Z","iopub.status.idle":"2023-12-23T14:14:27.728749Z","shell.execute_reply.started":"2023-12-23T14:14:27.722524Z","shell.execute_reply":"2023-12-23T14:14:27.727658Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Architecture of the Encoder","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\n\nlatent_dim = 10\n\n# Define your custom layers\ninputs = keras.Input(shape=(69, 69, 3))  # Fix the input layer\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(inputs)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Flatten()(x)\nx = layers.Dense(64, activation=\"relu\")(x)\nx = layers.Dense(32, activation=\"sigmoid\")(x)\n\n# Continue with your code\nz_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz = layers.Lambda(Sampling(), output_shape=(latent_dim,), name=\"sampling\")([z_mean, z_log_var])  # Assuming you have a Sampling layer or a Lambda layer named 'sampling'\n\n# Build the model\nencoder = keras.Model(inputs=inputs, outputs=[z_mean, z_log_var, z], name=\"encoder\")  # Adjust the base_model input\nencoder.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:44:44.141365Z","iopub.execute_input":"2023-12-23T14:44:44.142144Z","iopub.status.idle":"2023-12-23T14:44:44.314099Z","shell.execute_reply.started":"2023-12-23T14:44:44.142109Z","shell.execute_reply":"2023-12-23T14:44:44.311521Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Model: \"encoder\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_15 (InputLayer)       [(None, 69, 69, 3)]          0         []                            \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 35, 35, 64)           1792      ['input_15[0][0]']            \n                                                                                                  \n batch_normalization_43 (Ba  (None, 35, 35, 64)           256       ['conv2d_21[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 18, 18, 64)           36928     ['batch_normalization_43[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_44 (Ba  (None, 18, 18, 64)           256       ['conv2d_22[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 9, 9, 32)             18464     ['batch_normalization_44[0][0]\n                                                                    ']                            \n                                                                                                  \n flatten_6 (Flatten)         (None, 2592)                 0         ['conv2d_23[0][0]']           \n                                                                                                  \n dense_35 (Dense)            (None, 64)                   165952    ['flatten_6[0][0]']           \n                                                                                                  \n dense_36 (Dense)            (None, 32)                   2080      ['dense_35[0][0]']            \n                                                                                                  \n z_mean (Dense)              (None, 10)                   330       ['dense_36[0][0]']            \n                                                                                                  \n z_log_var (Dense)           (None, 10)                   330       ['dense_36[0][0]']            \n                                                                                                  \n sampling (Lambda)           (None, 10)                   0         ['z_mean[0][0]',              \n                                                                     'z_log_var[0][0]']           \n                                                                                                  \n==================================================================================================\nTotal params: 226388 (884.33 KB)\nTrainable params: 226132 (883.33 KB)\nNon-trainable params: 256 (1.00 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Architecture of the decoder","metadata":{}},{"cell_type":"code","source":"latent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(9*9*32, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((9, 9, 32))(x)\nx = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx=layers.BatchNormalization()(x)\nx = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx=layers.BatchNormalization()(x)\nx = layers.Conv2DTranspose(32, 3, activation=\"sigmoid\", strides=2, padding=\"same\")(x)\nx = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder_outputs = layers.Cropping2D(cropping=((3, 0), (3, 0)), data_format=None)(x)  # Adjust cropping\n\n# Crop or pad to get the desired shape 69*69*3\n\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:44:50.216283Z","iopub.execute_input":"2023-12-23T14:44:50.217171Z","iopub.status.idle":"2023-12-23T14:44:50.361353Z","shell.execute_reply.started":"2023-12-23T14:44:50.217136Z","shell.execute_reply":"2023-12-23T14:44:50.360474Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Model: \"decoder\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_16 (InputLayer)       [(None, 10)]              0         \n                                                                 \n dense_37 (Dense)            (None, 2592)              28512     \n                                                                 \n reshape_8 (Reshape)         (None, 9, 9, 32)          0         \n                                                                 \n conv2d_transpose_35 (Conv2  (None, 18, 18, 64)        18496     \n DTranspose)                                                     \n                                                                 \n batch_normalization_45 (Ba  (None, 18, 18, 64)        256       \n tchNormalization)                                               \n                                                                 \n conv2d_transpose_36 (Conv2  (None, 36, 36, 32)        18464     \n DTranspose)                                                     \n                                                                 \n batch_normalization_46 (Ba  (None, 36, 36, 32)        128       \n tchNormalization)                                               \n                                                                 \n conv2d_transpose_37 (Conv2  (None, 72, 72, 32)        9248      \n DTranspose)                                                     \n                                                                 \n conv2d_transpose_38 (Conv2  (None, 72, 72, 3)         867       \n DTranspose)                                                     \n                                                                 \n cropping2d_8 (Cropping2D)   (None, 69, 69, 3)         0         \n                                                                 \n=================================================================\nTotal params: 75971 (296.76 KB)\nTrainable params: 75779 (296.01 KB)\nNon-trainable params: 192 (768.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# VAE Model","metadata":{}},{"cell_type":"code","source":"\nclass VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super().__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = self.encoder(data)\n            reconstruction = self.decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                tf.reduce_sum(\n                    keras.losses.binary_crossentropy(data, reconstruction),\n                    axis=(1, 2),\n                )\n            )\n            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            total_loss = reconstruction_loss + kl_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n        }\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:26:42.335144Z","iopub.execute_input":"2023-12-23T14:26:42.336102Z","iopub.status.idle":"2023-12-23T14:26:42.346886Z","shell.execute_reply.started":"2023-12-23T14:26:42.336066Z","shell.execute_reply":"2023-12-23T14:26:42.345883Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train1, target, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:26:49.664418Z","iopub.execute_input":"2023-12-23T14:26:49.664798Z","iopub.status.idle":"2023-12-23T14:26:49.764786Z","shell.execute_reply.started":"2023-12-23T14:26:49.664768Z","shell.execute_reply":"2023-12-23T14:26:49.763961Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"df = np.concatenate([X_train, X_test], axis=0)\ndf = df.astype(\"float32\") / 255","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:26:53.518701Z","iopub.execute_input":"2023-12-23T14:26:53.519058Z","iopub.status.idle":"2023-12-23T14:26:54.036769Z","shell.execute_reply.started":"2023-12-23T14:26:53.519030Z","shell.execute_reply":"2023-12-23T14:26:54.035909Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Training to the minimum reconstruction loss","metadata":{}},{"cell_type":"code","source":"vae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\nhistory=vae.fit(mnist_digits, epochs=10, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:45:08.101336Z","iopub.execute_input":"2023-12-23T14:45:08.102696Z","iopub.status.idle":"2023-12-23T14:46:42.841935Z","shell.execute_reply.started":"2023-12-23T14:45:08.102651Z","shell.execute_reply":"2023-12-23T14:46:42.841043Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Epoch 1/10\n681/681 [==============================] - 15s 13ms/step - loss: 1337.0352 - reconstruction_loss: 1215.1970 - kl_loss: 6.6338\nEpoch 2/10\n681/681 [==============================] - 9s 13ms/step - loss: 1172.9487 - reconstruction_loss: 1160.6001 - kl_loss: 7.8416\nEpoch 3/10\n681/681 [==============================] - 9s 13ms/step - loss: 1163.1930 - reconstruction_loss: 1157.9260 - kl_loss: 7.4413\nEpoch 4/10\n681/681 [==============================] - 9s 13ms/step - loss: 1161.0558 - reconstruction_loss: 1155.7097 - kl_loss: 7.6172\nEpoch 5/10\n681/681 [==============================] - 8s 12ms/step - loss: 1161.3546 - reconstruction_loss: 1153.8108 - kl_loss: 7.8816\nEpoch 6/10\n681/681 [==============================] - 9s 13ms/step - loss: 1159.4403 - reconstruction_loss: 1152.9047 - kl_loss: 8.0152\nEpoch 7/10\n681/681 [==============================] - 8s 12ms/step - loss: 1162.7206 - reconstruction_loss: 1152.3563 - kl_loss: 8.0935\nEpoch 8/10\n681/681 [==============================] - 8s 12ms/step - loss: 1164.0598 - reconstruction_loss: 1151.7773 - kl_loss: 8.1251\nEpoch 9/10\n681/681 [==============================] - 8s 12ms/step - loss: 1159.8475 - reconstruction_loss: 1151.3937 - kl_loss: 8.1431\nEpoch 10/10\n681/681 [==============================] - 9s 13ms/step - loss: 1156.9613 - reconstruction_loss: 1151.2217 - kl_loss: 8.1465\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder.trainable=False# freeze the weights","metadata":{"execution":{"iopub.status.busy":"2023-12-23T14:46:50.766375Z","iopub.execute_input":"2023-12-23T14:46:50.766748Z","iopub.status.idle":"2023-12-23T14:46:50.771791Z","shell.execute_reply.started":"2023-12-23T14:46:50.766717Z","shell.execute_reply":"2023-12-23T14:46:50.770877Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"encoder.output","metadata":{"execution":{"iopub.status.busy":"2023-12-23T06:54:10.482345Z","iopub.execute_input":"2023-12-23T06:54:10.482698Z","iopub.status.idle":"2023-12-23T06:54:10.489117Z","shell.execute_reply.started":"2023-12-23T06:54:10.482669Z","shell.execute_reply":"2023-12-23T06:54:10.488171Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'z_mean')>,\n <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'z_log_var')>,\n <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'sampling')>]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Dense layer for the image classification","metadata":{}},{"cell_type":"code","source":"# Assuming you have the pretrained 'encoder' model\nencoded_vectors = encoder.get_layer('flatten_6').output  # Assuming the layer is named 'z'\n\n# Add a fully connected layer on top of the encoded vectors\nclassification_layer = layers.Dense(256, activation='relu')(encoded_vectors)\nclassification_layer=layers.BatchNormalization()(classification_layer)\nlayer1=layers.Dense(128, kernel_regularizer=keras.regularizers.l2(0.001),activation='relu')(classification_layer)\nlayer1=layers.Dropout(0.5)(layer1)\nlayer2=layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001),activation='relu')(layer1)\nlayer2=layers.Dropout(0.5)(layer2)\nlayer3=layers.Dense(32, kernel_regularizer=keras.regularizers.l2(0.001),activation='relu')(layer2)\nlayer3=layers.BatchNormalization()(layer3)\n# Add a separate fully connected layer for the sampling output (optional)\n\n# Add the final output layer for classification\noutput_layer = layers.Dense(10, activation='softmax')(layer3)\n\n# Create a new model with the frozen encoder input and the output_layer as output\nclassification_model = keras.Model(inputs=encoder.input, outputs=output_layer, name='classification_model')\n\n# Compile the model with an appropriate optimizer and loss for the MNIST classification task\nclassification_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\ndef lr_scheduler(epoch,lr):\n    if(epoch<=50):\n        lr=0.001\n    elif(epoch>50 & epoch <75):\n        lr=0.0001\n    else:\n        lr=0.00001\n    return lr\n# Create a LearningRateScheduler callback\nlr_scheduler_callback = keras.callbacks.LearningRateScheduler(lr_scheduler)\n# Train the new model\nhistory=classification_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test),callbacks=[lr_scheduler_callback])\n\n# Evaluate the model on the test set\naccuracy = classification_model.evaluate(X_test, y_test)[1]\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-12-23T15:02:43.237093Z","iopub.execute_input":"2023-12-23T15:02:43.237975Z","iopub.status.idle":"2023-12-23T15:08:04.610071Z","shell.execute_reply.started":"2023-12-23T15:02:43.237937Z","shell.execute_reply":"2023-12-23T15:08:04.609253Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Epoch 1/100\n545/545 [==============================] - 6s 7ms/step - loss: 1.9735 - accuracy: 0.4198 - val_loss: 1.4972 - val_accuracy: 0.5433 - lr: 0.0010\nEpoch 2/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.4660 - accuracy: 0.5483 - val_loss: 1.2991 - val_accuracy: 0.5703 - lr: 0.0010\nEpoch 3/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.3241 - accuracy: 0.5957 - val_loss: 1.3983 - val_accuracy: 0.5419 - lr: 0.0010\nEpoch 4/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.2354 - accuracy: 0.6140 - val_loss: 1.2620 - val_accuracy: 0.5977 - lr: 0.0010\nEpoch 5/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.1681 - accuracy: 0.6294 - val_loss: 1.1083 - val_accuracy: 0.6438 - lr: 0.0010\nEpoch 6/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.1055 - accuracy: 0.6395 - val_loss: 1.0596 - val_accuracy: 0.6502 - lr: 0.0010\nEpoch 7/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.0865 - accuracy: 0.6452 - val_loss: 0.9984 - val_accuracy: 0.6716 - lr: 0.0010\nEpoch 8/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.0447 - accuracy: 0.6585 - val_loss: 1.1832 - val_accuracy: 0.5795 - lr: 0.0010\nEpoch 9/100\n545/545 [==============================] - 3s 6ms/step - loss: 1.0185 - accuracy: 0.6597 - val_loss: 0.9797 - val_accuracy: 0.6773 - lr: 0.0010\nEpoch 10/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9899 - accuracy: 0.6692 - val_loss: 0.9379 - val_accuracy: 0.6766 - lr: 0.0010\nEpoch 11/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9914 - accuracy: 0.6670 - val_loss: 0.9291 - val_accuracy: 0.6782 - lr: 0.0010\nEpoch 12/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9686 - accuracy: 0.6725 - val_loss: 1.0079 - val_accuracy: 0.6475 - lr: 0.0010\nEpoch 13/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9583 - accuracy: 0.6789 - val_loss: 0.9640 - val_accuracy: 0.6569 - lr: 0.0010\nEpoch 14/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9403 - accuracy: 0.6787 - val_loss: 0.9688 - val_accuracy: 0.6805 - lr: 0.0010\nEpoch 15/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9299 - accuracy: 0.6854 - val_loss: 0.9003 - val_accuracy: 0.6943 - lr: 0.0010\nEpoch 16/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9087 - accuracy: 0.6932 - val_loss: 0.9266 - val_accuracy: 0.6904 - lr: 0.0010\nEpoch 17/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9142 - accuracy: 0.6917 - val_loss: 0.9364 - val_accuracy: 0.6787 - lr: 0.0010\nEpoch 18/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.9092 - accuracy: 0.6909 - val_loss: 0.9489 - val_accuracy: 0.7005 - lr: 0.0010\nEpoch 19/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8986 - accuracy: 0.6962 - val_loss: 0.8675 - val_accuracy: 0.7099 - lr: 0.0010\nEpoch 20/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8915 - accuracy: 0.7000 - val_loss: 0.8487 - val_accuracy: 0.7122 - lr: 0.0010\nEpoch 21/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8872 - accuracy: 0.7005 - val_loss: 0.9246 - val_accuracy: 0.6762 - lr: 0.0010\nEpoch 22/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8815 - accuracy: 0.7067 - val_loss: 0.9664 - val_accuracy: 0.6768 - lr: 0.0010\nEpoch 23/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8751 - accuracy: 0.7062 - val_loss: 0.9444 - val_accuracy: 0.6741 - lr: 0.0010\nEpoch 24/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8723 - accuracy: 0.7064 - val_loss: 0.8706 - val_accuracy: 0.7078 - lr: 0.0010\nEpoch 25/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8608 - accuracy: 0.7108 - val_loss: 0.9133 - val_accuracy: 0.6821 - lr: 0.0010\nEpoch 26/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8648 - accuracy: 0.7081 - val_loss: 1.0821 - val_accuracy: 0.6330 - lr: 0.0010\nEpoch 27/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8532 - accuracy: 0.7121 - val_loss: 0.9107 - val_accuracy: 0.6918 - lr: 0.0010\nEpoch 28/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8441 - accuracy: 0.7186 - val_loss: 0.9234 - val_accuracy: 0.6830 - lr: 0.0010\nEpoch 29/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8521 - accuracy: 0.7148 - val_loss: 0.9706 - val_accuracy: 0.6739 - lr: 0.0010\nEpoch 30/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8437 - accuracy: 0.7152 - val_loss: 0.8972 - val_accuracy: 0.6964 - lr: 0.0010\nEpoch 31/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8437 - accuracy: 0.7168 - val_loss: 0.8717 - val_accuracy: 0.7053 - lr: 0.0010\nEpoch 32/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8373 - accuracy: 0.7190 - val_loss: 0.8949 - val_accuracy: 0.6964 - lr: 0.0010\nEpoch 33/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8329 - accuracy: 0.7223 - val_loss: 0.9308 - val_accuracy: 0.6904 - lr: 0.0010\nEpoch 34/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8295 - accuracy: 0.7229 - val_loss: 0.8477 - val_accuracy: 0.7113 - lr: 0.0010\nEpoch 35/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8191 - accuracy: 0.7247 - val_loss: 0.9090 - val_accuracy: 0.6993 - lr: 0.0010\nEpoch 36/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8243 - accuracy: 0.7239 - val_loss: 0.9216 - val_accuracy: 0.6876 - lr: 0.0010\nEpoch 37/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8288 - accuracy: 0.7241 - val_loss: 0.8486 - val_accuracy: 0.7122 - lr: 0.0010\nEpoch 38/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8261 - accuracy: 0.7255 - val_loss: 0.9158 - val_accuracy: 0.6986 - lr: 0.0010\nEpoch 39/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8234 - accuracy: 0.7259 - val_loss: 0.8550 - val_accuracy: 0.7104 - lr: 0.0010\nEpoch 40/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8142 - accuracy: 0.7284 - val_loss: 1.0092 - val_accuracy: 0.6475 - lr: 0.0010\nEpoch 41/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8154 - accuracy: 0.7292 - val_loss: 0.8667 - val_accuracy: 0.7156 - lr: 0.0010\nEpoch 42/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8097 - accuracy: 0.7315 - val_loss: 0.9332 - val_accuracy: 0.7023 - lr: 0.0010\nEpoch 43/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8060 - accuracy: 0.7293 - val_loss: 0.9015 - val_accuracy: 0.7081 - lr: 0.0010\nEpoch 44/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7885 - accuracy: 0.7401 - val_loss: 1.0845 - val_accuracy: 0.6619 - lr: 0.0010\nEpoch 45/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7985 - accuracy: 0.7353 - val_loss: 0.9257 - val_accuracy: 0.7069 - lr: 0.0010\nEpoch 46/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8205 - accuracy: 0.7260 - val_loss: 0.9225 - val_accuracy: 0.6952 - lr: 0.0010\nEpoch 47/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7921 - accuracy: 0.7342 - val_loss: 0.8948 - val_accuracy: 0.7039 - lr: 0.0010\nEpoch 48/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7941 - accuracy: 0.7343 - val_loss: 0.9252 - val_accuracy: 0.6957 - lr: 0.0010\nEpoch 49/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7826 - accuracy: 0.7428 - val_loss: 1.0131 - val_accuracy: 0.6445 - lr: 0.0010\nEpoch 50/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7829 - accuracy: 0.7395 - val_loss: 0.9175 - val_accuracy: 0.7122 - lr: 0.0010\nEpoch 51/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.8060 - accuracy: 0.7319 - val_loss: 1.1124 - val_accuracy: 0.5733 - lr: 0.0010\nEpoch 52/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7581 - accuracy: 0.7455 - val_loss: 0.8114 - val_accuracy: 0.7248 - lr: 1.0000e-04\nEpoch 53/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7411 - accuracy: 0.7528 - val_loss: 0.8204 - val_accuracy: 0.7246 - lr: 1.0000e-04\nEpoch 54/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7312 - accuracy: 0.7587 - val_loss: 0.8028 - val_accuracy: 0.7269 - lr: 1.0000e-04\nEpoch 55/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7231 - accuracy: 0.7611 - val_loss: 0.8072 - val_accuracy: 0.7253 - lr: 1.0000e-04\nEpoch 56/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7129 - accuracy: 0.7677 - val_loss: 0.8057 - val_accuracy: 0.7260 - lr: 1.0000e-04\nEpoch 57/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7186 - accuracy: 0.7642 - val_loss: 0.8050 - val_accuracy: 0.7246 - lr: 1.0000e-04\nEpoch 58/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7098 - accuracy: 0.7642 - val_loss: 0.8052 - val_accuracy: 0.7266 - lr: 1.0000e-04\nEpoch 59/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7119 - accuracy: 0.7623 - val_loss: 0.8104 - val_accuracy: 0.7232 - lr: 1.0000e-04\nEpoch 60/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7086 - accuracy: 0.7638 - val_loss: 0.8038 - val_accuracy: 0.7239 - lr: 1.0000e-04\nEpoch 61/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.7011 - accuracy: 0.7684 - val_loss: 0.8079 - val_accuracy: 0.7250 - lr: 1.0000e-04\nEpoch 62/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6975 - accuracy: 0.7694 - val_loss: 0.8071 - val_accuracy: 0.7255 - lr: 1.0000e-04\nEpoch 63/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6925 - accuracy: 0.7709 - val_loss: 0.8114 - val_accuracy: 0.7296 - lr: 1.0000e-04\nEpoch 64/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6891 - accuracy: 0.7730 - val_loss: 0.8113 - val_accuracy: 0.7262 - lr: 1.0000e-04\nEpoch 65/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6939 - accuracy: 0.7681 - val_loss: 0.8031 - val_accuracy: 0.7257 - lr: 1.0000e-04\nEpoch 66/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6889 - accuracy: 0.7756 - val_loss: 0.8027 - val_accuracy: 0.7273 - lr: 1.0000e-04\nEpoch 67/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6912 - accuracy: 0.7673 - val_loss: 0.8143 - val_accuracy: 0.7305 - lr: 1.0000e-04\nEpoch 68/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6771 - accuracy: 0.7705 - val_loss: 0.8012 - val_accuracy: 0.7315 - lr: 1.0000e-04\nEpoch 69/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6792 - accuracy: 0.7742 - val_loss: 0.8135 - val_accuracy: 0.7271 - lr: 1.0000e-04\nEpoch 70/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6816 - accuracy: 0.7738 - val_loss: 0.8177 - val_accuracy: 0.7221 - lr: 1.0000e-04\nEpoch 71/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6838 - accuracy: 0.7724 - val_loss: 0.8078 - val_accuracy: 0.7347 - lr: 1.0000e-04\nEpoch 72/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6792 - accuracy: 0.7719 - val_loss: 0.8034 - val_accuracy: 0.7285 - lr: 1.0000e-04\nEpoch 73/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6675 - accuracy: 0.7772 - val_loss: 0.8165 - val_accuracy: 0.7255 - lr: 1.0000e-04\nEpoch 74/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6691 - accuracy: 0.7766 - val_loss: 0.8174 - val_accuracy: 0.7271 - lr: 1.0000e-04\nEpoch 75/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6666 - accuracy: 0.7764 - val_loss: 0.8104 - val_accuracy: 0.7250 - lr: 1.0000e-04\nEpoch 76/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6705 - accuracy: 0.7746 - val_loss: 0.8120 - val_accuracy: 0.7283 - lr: 1.0000e-04\nEpoch 77/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6622 - accuracy: 0.7778 - val_loss: 0.8113 - val_accuracy: 0.7315 - lr: 1.0000e-04\nEpoch 78/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6745 - accuracy: 0.7732 - val_loss: 0.8071 - val_accuracy: 0.7271 - lr: 1.0000e-04\nEpoch 79/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6622 - accuracy: 0.7785 - val_loss: 0.8098 - val_accuracy: 0.7262 - lr: 1.0000e-04\nEpoch 80/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6635 - accuracy: 0.7794 - val_loss: 0.8100 - val_accuracy: 0.7283 - lr: 1.0000e-04\nEpoch 81/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6532 - accuracy: 0.7816 - val_loss: 0.8115 - val_accuracy: 0.7271 - lr: 1.0000e-04\nEpoch 82/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6545 - accuracy: 0.7810 - val_loss: 0.8172 - val_accuracy: 0.7317 - lr: 1.0000e-04\nEpoch 83/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6562 - accuracy: 0.7810 - val_loss: 0.8279 - val_accuracy: 0.7262 - lr: 1.0000e-04\nEpoch 84/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6601 - accuracy: 0.7788 - val_loss: 0.8113 - val_accuracy: 0.7285 - lr: 1.0000e-04\nEpoch 85/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6458 - accuracy: 0.7847 - val_loss: 0.8325 - val_accuracy: 0.7283 - lr: 1.0000e-04\nEpoch 86/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6592 - accuracy: 0.7801 - val_loss: 0.8288 - val_accuracy: 0.7165 - lr: 1.0000e-04\nEpoch 87/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6468 - accuracy: 0.7843 - val_loss: 0.8219 - val_accuracy: 0.7269 - lr: 1.0000e-04\nEpoch 88/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6481 - accuracy: 0.7789 - val_loss: 0.8196 - val_accuracy: 0.7264 - lr: 1.0000e-04\nEpoch 89/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6469 - accuracy: 0.7841 - val_loss: 0.8172 - val_accuracy: 0.7287 - lr: 1.0000e-04\nEpoch 90/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6476 - accuracy: 0.7804 - val_loss: 0.8198 - val_accuracy: 0.7285 - lr: 1.0000e-04\nEpoch 91/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6375 - accuracy: 0.7828 - val_loss: 0.8178 - val_accuracy: 0.7280 - lr: 1.0000e-04\nEpoch 92/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6431 - accuracy: 0.7836 - val_loss: 0.8266 - val_accuracy: 0.7260 - lr: 1.0000e-04\nEpoch 93/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6390 - accuracy: 0.7879 - val_loss: 0.8143 - val_accuracy: 0.7253 - lr: 1.0000e-04\nEpoch 94/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6399 - accuracy: 0.7819 - val_loss: 0.8160 - val_accuracy: 0.7289 - lr: 1.0000e-04\nEpoch 95/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6360 - accuracy: 0.7894 - val_loss: 0.8206 - val_accuracy: 0.7289 - lr: 1.0000e-04\nEpoch 96/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6423 - accuracy: 0.7861 - val_loss: 0.8208 - val_accuracy: 0.7292 - lr: 1.0000e-04\nEpoch 97/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6330 - accuracy: 0.7895 - val_loss: 0.8164 - val_accuracy: 0.7283 - lr: 1.0000e-04\nEpoch 98/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6441 - accuracy: 0.7837 - val_loss: 0.8135 - val_accuracy: 0.7271 - lr: 1.0000e-04\nEpoch 99/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6349 - accuracy: 0.7877 - val_loss: 0.8268 - val_accuracy: 0.7278 - lr: 1.0000e-04\nEpoch 100/100\n545/545 [==============================] - 3s 6ms/step - loss: 0.6350 - accuracy: 0.7856 - val_loss: 0.8254 - val_accuracy: 0.7262 - lr: 1.0000e-04\n137/137 [==============================] - 0s 3ms/step - loss: 0.8254 - accuracy: 0.7262\nTest Accuracy: 72.62%\n","output_type":"stream"}]},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=history.epoch, y=history.history['accuracy'], mode='lines', name='Train accuracy'))\nfig.add_trace(go.Scatter(x=history.epoch, y=history.history['val_accuracy'], mode='lines', name='Validation accuracy'))\n\nfig.update_layout(title='Training and Validation accuracy Over Epochs',\n                  xaxis=dict(title='Epochs'),\n                  yaxis=dict(title='accuracy'),\n                  template='plotly_dark')\n\n# Show the plot\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T15:08:55.546279Z","iopub.execute_input":"2023-12-23T15:08:55.546917Z","iopub.status.idle":"2023-12-23T15:08:55.591197Z","shell.execute_reply.started":"2023-12-23T15:08:55.546883Z","shell.execute_reply":"2023-12-23T15:08:55.590276Z"},"trusted":true},"execution_count":57,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"94276023-e3d6-4a38-975f-f64e3c57dda4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"94276023-e3d6-4a38-975f-f64e3c57dda4\")) {                    Plotly.newPlot(                        \"94276023-e3d6-4a38-975f-f64e3c57dda4\",                        [{\"mode\":\"lines\",\"name\":\"Train accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.4198416471481323,0.5482556819915771,0.5956506729125977,0.6140119433403015,0.6293894648551941,0.6395455598831177,0.6451687216758728,0.6584805846214294,0.6596855521202087,0.669153094291687,0.6669726967811584,0.6725384593009949,0.6789075136184692,0.6787353754043579,0.6854487061500549,0.6931948661804199,0.6917030215263367,0.6908997297286987,0.6962359547615051,0.7000229358673096,0.7004820108413696,0.7066789269447327,0.7062198519706726,0.7064493894577026,0.7108101844787598,0.7080559730529785,0.7120725512504578,0.7186137437820435,0.7147693634033203,0.7151709794998169,0.7167776226997375,0.7189580202102661,0.7222859859466553,0.7228597402572632,0.7246959209442139,0.7238925695419312,0.7240647077560425,0.7254992127418518,0.7259008288383484,0.7283681631088257,0.7291714549064636,0.7314665913581848,0.7292861938476562,0.7401308417320251,0.735253632068634,0.7260156273841858,0.7341634035110474,0.7343355417251587,0.742770254611969,0.7394996285438538,0.7319256663322449,0.7455244660377502,0.7527542114257812,0.7586641907691956,0.7610741257667542,0.7677301168441772,0.7641726136207581,0.7641726136207581,0.7623364925384521,0.7638283371925354,0.7683612704277039,0.7693940997123718,0.770943284034729,0.7729515433311462,0.7680743336677551,0.7755910158157349,0.7673284411430359,0.7705416679382324,0.7742139101028442,0.773754894733429,0.7723777890205383,0.771918773651123,0.7771975994110107,0.7765664458274841,0.7763943076133728,0.7746155858039856,0.7778287529945374,0.7731810808181763,0.7784599661827087,0.779435396194458,0.7815583944320679,0.78098464012146,0.7810419797897339,0.7788042426109314,0.7847142815589905,0.7800665497779846,0.7842552065849304,0.7788615822792053,0.7841404676437378,0.7803534269332886,0.7827633619308472,0.7836240530014038,0.7879274487495422,0.7819026708602905,0.7894193530082703,0.786148726940155,0.7895340919494629,0.7837387919425964,0.787697970867157,0.7855749130249023],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Validation accuracy\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.5432637333869934,0.5703465938568115,0.5418866276741028,0.5976589322090149,0.6437916159629822,0.6502180695533752,0.6715630292892456,0.5795271992683411,0.6773008704185486,0.676612377166748,0.6782189607620239,0.647463858127594,0.6568740010261536,0.6805140972137451,0.6942850351333618,0.6903833150863647,0.6786779761314392,0.7004820108413696,0.7098921537399292,0.7121872901916504,0.676153302192688,0.6768418550491333,0.6740877032279968,0.7078264951705933,0.6821207404136658,0.633004367351532,0.6917603611946106,0.6830387711524963,0.6738581657409668,0.6963506937026978,0.705301821231842,0.6963506937026978,0.6903833150863647,0.711269199848175,0.6993343830108643,0.6876291036605835,0.7121872901916504,0.698645830154419,0.7103511691093445,0.647463858127594,0.7156299948692322,0.7023181319236755,0.7080559730529785,0.661923348903656,0.7069084048271179,0.6952031254768372,0.7039247155189514,0.6956621408462524,0.6444801688194275,0.7121872901916504,0.573330283164978,0.7248106598854065,0.7245811223983765,0.7268763184547424,0.7252696752548218,0.7259582281112671,0.7245811223983765,0.7266467809677124,0.7232040166854858,0.7238925695419312,0.7250401377677917,0.7254992127418518,0.7296304702758789,0.7261877655982971,0.7257286906242371,0.7273353338241577,0.7305485606193542,0.7314665913581848,0.7271057963371277,0.7220564484596252,0.7346798181533813,0.7284829020500183,0.7254992127418518,0.7271057963371277,0.7250401377677917,0.7282533645629883,0.7314665913581848,0.7271057963371277,0.7261877655982971,0.7282533645629883,0.7271057963371277,0.7316961288452148,0.7261877655982971,0.7284829020500183,0.7282533645629883,0.7165480852127075,0.7268763184547424,0.7264172434806824,0.7287124395370483,0.7284829020500183,0.728023886680603,0.7259582281112671,0.7252696752548218,0.7289419174194336,0.7289419174194336,0.7291714549064636,0.7282533645629883,0.7271057963371277,0.727794349193573,0.7261877655982971],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#f2f5fa\"},\"error_y\":{\"color\":\"#f2f5fa\"},\"marker\":{\"line\":{\"color\":\"rgb(17,17,17)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"baxis\":{\"endlinecolor\":\"#A2B1C6\",\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"minorgridcolor\":\"#506784\",\"startlinecolor\":\"#A2B1C6\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"line\":{\"color\":\"#283442\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#506784\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"header\":{\"fill\":{\"color\":\"#2a3f5f\"},\"line\":{\"color\":\"rgb(17,17,17)\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#f2f5fa\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#f2f5fa\"},\"geo\":{\"bgcolor\":\"rgb(17,17,17)\",\"lakecolor\":\"rgb(17,17,17)\",\"landcolor\":\"rgb(17,17,17)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#506784\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"dark\"},\"paper_bgcolor\":\"rgb(17,17,17)\",\"plot_bgcolor\":\"rgb(17,17,17)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"radialaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"yaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"},\"zaxis\":{\"backgroundcolor\":\"rgb(17,17,17)\",\"gridcolor\":\"#506784\",\"gridwidth\":2,\"linecolor\":\"#506784\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#C8D4E3\"}},\"shapedefaults\":{\"line\":{\"color\":\"#f2f5fa\"}},\"sliderdefaults\":{\"bgcolor\":\"#C8D4E3\",\"bordercolor\":\"rgb(17,17,17)\",\"borderwidth\":1,\"tickwidth\":0},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"},\"bgcolor\":\"rgb(17,17,17)\",\"caxis\":{\"gridcolor\":\"#506784\",\"linecolor\":\"#506784\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"updatemenudefaults\":{\"bgcolor\":\"#506784\",\"borderwidth\":0},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#283442\",\"linecolor\":\"#506784\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#283442\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Training and Validation accuracy Over Epochs\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"accuracy\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('94276023-e3d6-4a38-975f-f64e3c57dda4');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"markdown","source":"We can see there is little bit overfitting but when I used simple CNN ,even I have used Transfer Learning I am just able to get 72% accuracy with 66% validation accuracy,but using these semi-supervised learning we get better results ,which is an amazing thing.","metadata":{}}]}